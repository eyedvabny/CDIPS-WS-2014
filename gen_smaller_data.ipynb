{
 "metadata": {
  "name": "",
  "signature": "sha256:c5c984afc62607d25e8364825b378cdacda41306019d2f061ee657fd2b0f7296"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 2,
     "metadata": {},
     "source": [
      "Playing around with training and testing datasets"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 1
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "The test and training data live in the data directory in the default filestructure."
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "From the Kaggle description:\n",
      "* **itemid** - unique identifier of each ad\n",
      "* **category** \u2013 1st level category of an ad\n",
      "* **subcategory** \u2013 2nd level category of an ad\n",
      "* **title** \u2013 name of the Ad\n",
      "* **description** \u2013 Full text with ad description\n",
      "* **attrs** \u2013 additional parameters of the ad in JSON format. Each parameter has its name and its value. E.g if you are selling bmw z1 car, you would have {\u201ccar brand\u201d:\u201dbmw\u201d, \u201ccar model\u201d:\u201dz1\u201d}\n",
      "* **price** \u2013 final price of ad in Russian rubles\n",
      "* **is_proved** \u2013 Additional data column that is available in the training only. Not to be used as a direct modeling attribute. This flag is provided only for blocked ads. It indicates that ad was blocked by an experienced moderator. Because humans do make errors it is likely (though not proven) that ads blocked by experienced moderator who should contain larger % of actually illicit content.\n",
      "* **is_blocked** \u2013 Boolean target variable. This is the column to predict.\n",
      "* **phones_cnt** \u2013 Number of contact phones that we found in ad description. Some sellers provide their contact phone numbers in ad description. If it was the case we would replace this phone number with @@PHONE@@ in description.\n",
      "* **emails_cnt** \u2013 Number of emails that we found in ad description. Some sellers provide their emails in ad description. If it was the case we would replace this email with @@EMAIL@@ in description.\n",
      "* **urls_cnt** \u2013 Number of urls that we found in ad description. Some sellers provide urls in ad description. If it was the case we would replace this email with @@URL@@ in description.\n",
      "* **close_hours** \u2013 Available in train only! Number of hours as a real number how long ad was live on avito. The more hours it was live and was not blocked it is more likely that it does not contain illicit content and it was not missed by moderators by error."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "chunk_size=500000\n",
      "\n",
      "train_file_len = 0;\n",
      "num_blocked = 0;\n",
      "num_non_blocked = 0;\n",
      "num_proved = 0;\n",
      "num_non_proved = 0;\n",
      "\n",
      "d_train = pd.read_csv(\"data/avito_train.tsv\",sep='\\t',chunksize=chunk_size);\n",
      "\n",
      "for chunk in d_train:\n",
      "    train_file_len += len(chunk)\n",
      "    g_by_block = chunk.groupby('is_blocked').size()\n",
      "    g_by_prov = chunk.groupby('is_proved').size()\n",
      "    \n",
      "    num_blocked += g_by_block[1]\n",
      "    num_non_blocked += g_by_block[0]\n",
      "    num_proved += g_by_prov[1]\n",
      "    num_non_proved += g_by_prov[0]\n",
      "\n",
      "print(\"Training set has %d rows\"%train_file_len)\n",
      "print(\"%d ads were illicit; %d were legal (%f of total ads)\"%\n",
      "      (num_blocked,num_non_blocked,num_blocked/float(train_file_len)))\n",
      "print(\"%d of blocked ads were proved; %d were blocked by other means (%f of blocked ads)\"%\n",
      "      (num_proved,num_non_proved,num_proved/float(num_blocked)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training set has 3995803 rows\n",
        "274996 ads were illicit; 3720807 were legal (0.068821 of total ads)\n",
        "83810 of blocked ads were proved; 191186 were blocked by other means (0.304768 of blocked ads)\n"
       ]
      }
     ],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_test = pd.read_csv(\"data/avito_test.tsv\",sep='\\t',chunksize=chunk_size);\n",
      "test_file_len = sum([len(chunk) for chunk in d_test])\n",
      "print(\"Testing set has %d rows\"%test_file_len)\n",
      "print(\"Ratio of test to train is %f\"%(test_file_len/float(train_file_len)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Testing set has 1351242 rows\n",
        "Ratio of test to train is 0.338165\n"
       ]
      }
     ],
     "prompt_number": 3
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "So we want to take a sliver from the training set while maintaining the ratios. "
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "train_fract = 0.25 #Pick how much of the train data we want to end up using\n",
      "\n",
      "# We are building both training and cross-testing from the training data\n",
      "fract_to_extract = train_fract * (1+test_file_len/float(train_file_len))\n",
      "\n",
      "# Filtering function for picking out the right elements from the chunk\n",
      "def sample_chunk(chunk,fract):\n",
      "    # Estimate how many of this chunk's elements we want to extract\n",
      "    num_to_read = int(fract * len(chunk))\n",
      "    \n",
      "    # Pick out that many indices from this chunk\n",
      "    rows = np.random.choice(chunk.index.values,num_to_read,replace=False)\n",
      "    \n",
      "    # Append only these rows to our dataframe\n",
      "    return chunk.ix[rows]\n",
      "    \n",
      "# Grossly inefficient to re-read the entire file but easier for readability\n",
      "d_train = pd.read_csv(\"data/avito_train.tsv\",sep='\\t',chunksize=chunk_size);\n",
      "d_train_sub = pd.concat([sample_chunk(chunk,fract_to_extract) for chunk in d_train])"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 4
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Split the new dataset into training and cross-validation sets:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "num_in_train = int(train_fract * train_file_len)\n",
      "d_train = d_train_sub.iloc[:num_in_train]\n",
      "d_test = d_train_sub.iloc[num_in_train:]\n",
      "print(\"Training has %d elements and Test has %d elements\"%(len(d_train),len(d_test)))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Training has 998950 elements and Test has 337806 elements\n"
       ]
      }
     ],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Confirm whether the ratios are still approximately the same as what we see in full training set:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g_by_block = d_train.groupby('is_blocked').size()\n",
      "g_by_prov = d_train.groupby('is_proved').size()\n",
      "\n",
      "print(\"Stats for new training set:\")\n",
      "print(\"%d ads were illicit; %d were legal (%f of total ads)\"%\n",
      "      (g_by_block[1],g_by_block[0],g_by_block[1]/float(len(d_train))))\n",
      "print(\"%d of blocked ads were proved; %d were blocked by other means (%f of blocked ads)\"%\n",
      "      (g_by_prov[1],g_by_prov[0],g_by_prov[1]/float(g_by_block[1])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Stats for new training set:\n",
        "68861 ads were illicit; 930089 were legal (0.068933 of total ads)\n",
        "20965 of blocked ads were proved; 47896 were blocked by other means (0.304454 of blocked ads)\n"
       ]
      }
     ],
     "prompt_number": 6
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "g_by_block = d_test.groupby('is_blocked').size()\n",
      "g_by_prov = d_test.groupby('is_proved').size()\n",
      "\n",
      "print(\"Stats for new testing set:\")\n",
      "print(\"%d ads were illicit; %d were legal (%f of total ads)\"%\n",
      "      (g_by_block[1],g_by_block[0],g_by_block[1]/float(len(d_test))))\n",
      "print(\"%d of blocked ads were proved; %d were blocked by other means (%f of blocked ads)\"%\n",
      "      (g_by_prov[1],g_by_prov[0],g_by_prov[1]/float(g_by_block[1])))"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "Stats for new testing set:\n",
        "23256 ads were illicit; 314550 were legal (0.068844 of total ads)\n",
        "7047 of blocked ads were proved; 16209 were blocked by other means (0.303019 of blocked ads)\n"
       ]
      }
     ],
     "prompt_number": 7
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Looks like we're good to go! Let's save these lists for future use"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "d_train.to_csv(\"data/new_train.tsv\",sep=\"\\t\")\n",
      "d_test.to_csv(\"data/new_test.tsv\",sep=\"\\t\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 8
    }
   ],
   "metadata": {}
  }
 ]
}