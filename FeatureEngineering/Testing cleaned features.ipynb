{
 "metadata": {
  "name": "",
  "signature": "sha256:32886a062dd133cf87ee5179290dad5aa36732343c0bb5b0f70d619d11e3cfb9"
 },
 "nbformat": 3,
 "nbformat_minor": 0,
 "worksheets": [
  {
   "cells": [
    {
     "cell_type": "heading",
     "level": 1,
     "metadata": {},
     "source": [
      "Testing cleaned dataset"
     ]
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Reading train dataset - building pandas dataframe"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "As a beginning, I read the entire dataset into a single pandas dataframe. The *read_tabe* method deals with missing values (inserts **NA**-s) and automatically recognizes *int*, *float* and even *UTF8* strings. Once we have read the table, we dump it into a binary format to make it easier to load again."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import pandas as pd\n",
      "import pandas as pd\n",
      "import matplotlib.pyplot as plt\n",
      "import datetime\n",
      "import random\n",
      "import numpy as np\n",
      "import processFeatures as pF\n",
      "\n",
      "%matplotlib inline"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 2
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "# The name of the training dataset\n",
      "fileName = \"avito_train.tsv\" # File name\n",
      "\n",
      "# Reading the whole dataset\n",
      "df = pd.io.parsers.read_table(fileName, sep='\\t', header=0, index_col=0)\n",
      "\n",
      "# Dump into a pkl file:\n",
      "df.to_pickle(\"Whole_training_set.pkl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 9
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Ok, if we reload the ipython workbook the second time, we don't need to reopen the tsv file. Just the following one:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "df = pd.read_pickle(\"Whole_training_set.pkl\")"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 3
    },
    {
     "cell_type": "heading",
     "level": 3,
     "metadata": {},
     "source": [
      "Testing if the cleaning scripts can run without any problems"
     ]
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "We call all the loops of the *processFeatures* script, and store the results in an array, then we store the result in a pandas dataframe."
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "prices = pF.price(df.price)\n",
      "urls = pF.url_cnt(df.urls_cnt)\n",
      "phones = pF.phone_cnt(df.phones_cnt)\n",
      "emails = pF.emails_cnt(df.emails_cnt)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 5
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's combine those \"cleared\" values into a single dataframe together with the subcategory:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "features = pd.concat([pd.get_dummies(prices),\n",
      "    pd.get_dummies(urls), \n",
      "    pd.get_dummies(phones),\n",
      "    pd.get_dummies(emails)],axis=1)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [],
     "prompt_number": 32
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "len(features)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "metadata": {},
       "output_type": "pyout",
       "prompt_number": 29,
       "text": [
        "7991606"
       ]
      }
     ],
     "prompt_number": 29
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's try a prediction of using Dillon's [script](https://github.com/eyedvabny/CDIPS-WS-2014/blob/master/bayes_benchmark.py) at first:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.naive_bayes import MultinomialNB\n",
      "from sklearn.metrics import classification_report\n",
      "from sklearn.cross_validation import train_test_split\n",
      "\n",
      "dummySubcat = pd.get_dummies(df.subcategory)\n",
      "\n",
      "features_train, features_test, target_train, target_test =\\\n",
      "    train_test_split(dummySubcat, df.is_blocked, test_size = 0.25)\n",
      "\n",
      "bayes = MultinomialNB()\n",
      "bayes.fit(features_train, target_train)\n",
      "prediction_float = bayes.predict(features_test)\n",
      "prediction = np.round(prediction_float)\n",
      "print classification_report(target_test, prediction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.94      1.00      0.97    929998\n",
        "          1       0.78      0.07      0.13     68953\n",
        "\n",
        "avg / total       0.92      0.93      0.91    998951\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 23
    },
    {
     "cell_type": "markdown",
     "metadata": {},
     "source": [
      "Now, let's add the other features as well:"
     ]
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [
      "\n",
      "features_train, features_test, target_train, target_test =\\\n",
      "    train_test_split(features, df.is_blocked, test_size = 0.25)\n",
      "\n",
      "bayes = MultinomialNB()\n",
      "bayes.fit(features_train, target_train)\n",
      "prediction_float = bayes.predict(features_test)\n",
      "prediction = np.round(prediction_float)\n",
      "print classification_report(target_test, prediction)"
     ],
     "language": "python",
     "metadata": {},
     "outputs": [
      {
       "output_type": "stream",
       "stream": "stdout",
       "text": [
        "             precision    recall  f1-score   support\n",
        "\n",
        "          0       0.93      1.00      0.96    930291\n",
        "          1       0.38      0.01      0.03     68660\n",
        "\n",
        "avg / total       0.89      0.93      0.90    998951\n",
        "\n"
       ]
      }
     ],
     "prompt_number": 33
    },
    {
     "cell_type": "code",
     "collapsed": false,
     "input": [],
     "language": "python",
     "metadata": {},
     "outputs": []
    }
   ],
   "metadata": {}
  }
 ]
}